{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Players with low potentials but high actual Rating\n",
    "- Label Players has a potential higher than 83 but never reaches this potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERTRAINING = False\n",
    "CV = 5\n",
    "SCORING = ''\n",
    "CLASS_WEIGHTS = 'balanced'\n",
    "EXPERIEMENT_NAME = \"offense_potential_predictor_regression\"\n",
    "RUN_NAME = None\n",
    "TARGET_OVERALL = 80\n",
    "\n",
    "PLAYER_ATTRIBUTES = [ 'central','winger','offense','Finishing',  'ShortPassing', 'Volleys', 'Dribbling',  'FKAccuracy', 'LongPassing', 'BallControl',\n",
    "                      'Acceleration', 'SprintSpeed', 'Agility',    'Reactions', 'Balance', \n",
    "                      'ShotPower', 'Jumping',  'LongShots', 'Positioning', 'Vision' ]\n",
    "# PLAYER_ATTRIBUTES = [ 'Age' ,'Dribbling',  'FKAccuracy',  'BallControl','ShotPower','Positioning', 'Penalties' ]\n",
    "PLAYER_ATTRIBUTES = [  'central','offense','Age','Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys', 'Dribbling', 'Curve', 'FKAccuracy', 'LongPassing', 'BallControl',\n",
    "                      'Acceleration', 'SprintSpeed', 'Agility', 'GKPositioning', 'GKReflexes', 'Composure', 'Defensive awareness', 'Reactions', 'Balance', \n",
    "                      'ShotPower', 'Jumping', 'Stamina', 'Strength', 'LongShots', 'Aggression', 'Interceptions', 'Positioning', 'Vision', 'Penalties', 'Marking', \n",
    "                      'StandingTackleshooting_technique', 'SlidingTackle', 'GKDiving', 'GKHandling', 'GKKicking']\n",
    "PLAYER_ATTRIBUTES = ['Reactions', 'age_based_Stamina', 'Positioning', 'ShortPassing',  'Dribbling', 'BallControl',    'Aggression',   'Vision',  'SprintSpeed','shooting']\n",
    "PLAYER_ATTRIBUTES = ['Crossing', 'Finishing','shooting_technique','mental'\n",
    "       'ShortPassing', 'Volleys', 'Dribbling', 'Curve', 'FKAccuracy',\n",
    "       'LongPassing', 'BallControl',  'SprintSpeed', 'Agility',\n",
    "       'Reactions', 'Balance', 'ShotPower', 'Jumping', 'Stamina', 'Strength',\n",
    "       'LongShots', 'Aggression',  'Positioning', 'Vision',\n",
    "       'Penalties',  \n",
    "        'youth_player', 'shooting', \n",
    "       'mental', 'physique', 'Speed', 'ball_handling', 'age_based_Reactions',\n",
    "       'age_based_physique', 'age_based_shooting_technique',\n",
    "       'age_based_Stamina', 'age_based_Positioning', 'age_based_Vision',\n",
    "       'age_based_Finishing', 'age_based_BallControl']\n",
    "\n",
    "PLAYER_ATTRIBUTES = [ 'age_based_shooting','shooting', 'ShortPassing','Dribbling',    'BallControl',\n",
    "                     'SprintSpeed', 'Agility','Composure', 'Reactions', \n",
    "                       'age_based_Stamina', 'Aggression', 'Interceptions', 'Positioning', 'age_based_Vision']\n",
    "\n",
    "PLAYER_ATTRIBUTES = ['Crossing', 'Finishing','shooting_technique','mental',\n",
    "       'ShortPassing', 'Volleys', 'Dribbling', 'Curve', 'FKAccuracy',\n",
    "       'LongPassing', 'BallControl',  'SprintSpeed', 'Agility',\n",
    "       'Reactions', 'Balance', 'ShotPower', 'Jumping', 'Stamina', 'Strength',\n",
    "       'LongShots', 'Aggression',  'Positioning', 'Vision',\n",
    "       'Penalties',          'youth_player', 'shooting', \n",
    "       'mental', 'physique', 'Speed', 'ball_handling', 'age_based_Reactions',\n",
    "       'age_based_physique', 'age_based_shooting_technique',\n",
    "       'age_based_Stamina', 'age_based_Positioning', 'age_based_Vision',\n",
    "       'age_based_Finishing', 'age_based_BallControl']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def find_and_append_module_path():\n",
    "    current_dir = os.getcwd()\n",
    "    substring_to_find = 'statsfaction'\n",
    "    index = current_dir.rfind(substring_to_find)\n",
    "    \n",
    "    if index != -1:\n",
    "        # Extract the directory path up to and including the last \"mypath\" occurrence\n",
    "        new_dir = current_dir[:index + (len(substring_to_find))]\n",
    "\n",
    "        # Change the current working directory to the new directory\n",
    "        os.chdir(new_dir)\n",
    "        sys.path.append(new_dir)\n",
    "        # Verify the new current directory\n",
    "        print(\"New current directory:\", os.getcwd())\n",
    "    else:\n",
    "        print(\"No 'mypath' found in the current directory\")\n",
    "find_and_append_module_path()\n",
    "os.getcwd()\n",
    "\n",
    "from src.sport_analytics.model.prepare import add_features_raw_datadf_raw\n",
    "from src.sport_analytics.model.eval import plot_feature_importance,plot_shap_summary,plot_auc_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_prime = \"\"\"\n",
    "SELECT max(Age) as prime_age,* FROM(SELECT MAX(Overall) AS PrimeOverall,*\n",
    "  FROM fifa\n",
    "  GROUP BY ID ) \n",
    "  GROUP BY ID\n",
    "  order by PrimeOverall DESC;\n",
    "\"\"\"\n",
    "\n",
    "sql_potentials = f\"\"\"\n",
    "SELECT min(Age) as potential_age,* FROM  (SELECT *,Potential as max_potential FROM fifa WHERE Potential>={TARGET_OVERALL})\n",
    "GROUP BY ID\n",
    "order by potential DESC;\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "DATABASE_PATH = \"data/sport_analytics/database/football.db\"\n",
    "# Step 1: Establish a database connection\n",
    "conn = sqlite3.connect(DATABASE_PATH)\n",
    "\n",
    "df_potentials = pd.read_sql_query(sql_potentials, conn)\n",
    "df_prime = pd.read_sql_query(sql_prime, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "df_potentials = df_potentials.set_index(['ID'])\n",
    "df_prime = df_prime.set_index(['ID'])\n",
    "\n",
    "df_raw = df_potentials.join(df_prime[[\"prime_age\",\"PrimeOverall\"]])\n",
    "df_raw = df_raw.reset_index(['ID'])\n",
    "df_raw = add_features_raw_datadf_raw(df_raw)\n",
    "\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.PrimeOverall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "year_to_category = {2011: 'drop', 2012: 'train', 2013: 'train', 2014: 'train', 2015: 'train', 2016: 'train', 2017: 'train', 2018: 'train', 2019: 'test', 2020: 'test', 2021: 'test', 2022: 'test', 2023: 'valid', 2024: 'valid'}\n",
    "df['set'] = df.index.get_level_values('FIFA').values\n",
    "# Apply the mapping to the \"FIFA\" column\n",
    "df['set'] = df['set'].map(year_to_category)\n",
    "\n",
    "df_potentials = df[(df.set==\"valid\")&(df.Overall<TARGET_OVERALL)&(df.Age<26)&(df.Potential>=TARGET_OVERALL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[df.prime_age>df.potential_age]\n",
    "df['target'] = df.PrimeOverall\n",
    "df = df[df.potential_age<26]\n",
    "df = df[df.offense>0.5]\n",
    "print(df.target.value_counts())\n",
    "PREDICTION_NAME = \"Offense\"\n",
    "\n",
    "df_processed = df.copy()\n",
    "df_processed.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.best_position.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"potential_age\",\"Age\",\"prime_age\",\"max_potential\",\"Potential\",\"Overall\",\"PrimeOverall\",\"target\",\"set\",\"best_position\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "#     df = df[[any(pos in i for pos in ['CF', 'LW', 'ST', 'RW']) for i in df['Position']]]\n",
    "#     df.shape\n",
    "# else:\n",
    "#     select_position = lambda x: x in [\"ST\",\"CF\",\"LW\",\"RW\"]\n",
    "#     df[\"select\"] = df['Position'].apply(select_position)\n",
    "#     df = df[df[\"select\"]]\n",
    "#     df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deskriptive Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(exclude='object').corr()['target'].round(2).sort_values().head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Age<20].describe().round(0).compare(df[df.Age>=20].describe().round(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_processed.fillna(0)\n",
    "df_potentials = df_potentials.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_processed.drop(\"target\", axis=1, errors='ignore')\n",
    "y = df['target']  # Use df_processed here instead of df\n",
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "if False:\n",
    "    # Step 1: Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train = X_train[PLAYER_ATTRIBUTES]\n",
    "    X_test = X_test[PLAYER_ATTRIBUTES]\n",
    "\n",
    "else:\n",
    "\n",
    "    X_train = X[X.set==\"train\"][PLAYER_ATTRIBUTES]\n",
    "    y_train = y[X.set==\"train\"]\n",
    "\n",
    "    X_test = X[X.set==\"test\"][PLAYER_ATTRIBUTES]\n",
    "    y_test = y[X.set==\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load your dataset or replace df_processed and df with your data\n",
    "# df_processed = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Step 2: Initialize a StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Step 3: Fit the scaler on the training data and transform both training \n",
    "# and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "df_potentials_scaled = scaler.transform(df_potentials[PLAYER_ATTRIBUTES].fillna(0))\n",
    "\n",
    "# Step 4: Create new DataFrames with the scaled data while preserving the index and columns\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, index=X_train.index, columns=PLAYER_ATTRIBUTES)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, index=X_test.index, columns=PLAYER_ATTRIBUTES)\n",
    "df_potentials_scaled_df = pd.DataFrame(df_potentials_scaled, index=df_potentials.index, columns=PLAYER_ATTRIBUTES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparametertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if HYPERTRAINING:\n",
    "    def objective(trial):\n",
    "        # Define hyperparameters to optimize\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 8),\n",
    "            'min_samples_split': trial.suggest_float('min_samples_split', 0.1, 1.0),  # Adjust the range\n",
    "            'min_samples_leaf': trial.suggest_float('min_samples_leaf', 0.1, 0.5),  # Adjust the range\n",
    "            'max_features': trial.suggest_float('max_features', 0.6, 1.0),\n",
    "            'criterion': 'entropy',  # or 'entropy' depending on your problem\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        # Implement cross-validation\n",
    "        cv_scores = cross_val_score(RandomForestClassifier(**params), X_train_scaled_df, y_train, cv=CV, scoring=SCORING)\n",
    "        mean_auc = cv_scores.mean()\n",
    "\n",
    "        return mean_auc\n",
    "\n",
    "    # Create an Optuna study for maximizing AUC\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)  # You can increase n_trials for more optimization\n",
    "\n",
    "    PARAMS_RF = study.best_params\n",
    "    best_auc = study.best_value\n",
    "\n",
    "    print(\"Best hyperparameters:\", PARAMS_RF)\n",
    "    print(f\"Best {SCORING}:\", best_auc)\n",
    "else:\n",
    "    PARAMS_RF = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if HYPERTRAINING:\n",
    "    def objective(trial):\n",
    "        # Define hyperparameters to optimize\n",
    "        params = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 12),\n",
    "            'min_samples_split': trial.suggest_float('min_samples_split', 0.1, 1.0),  # Adjust the range\n",
    "            'min_samples_leaf': trial.suggest_float('min_samples_leaf', 0.1, 0.5),  # Adjust the range\n",
    "            'max_features': trial.suggest_float('max_features', 0.1, 1.0),\n",
    "            'criterion': 'gini',  # or 'entropy' depending on your problem\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        # Create the Decision Tree classifier with the given hyperparameters\n",
    "        clf = DecisionTreeClassifier(**params)\n",
    "\n",
    "        # Implement cross-validation to calculate mean AUC\n",
    "        cv_scores = cross_val_score(clf, X_train_scaled_df, y_train, cv=CV, scoring='recall_macro')\n",
    "        mean_auc = cv_scores.mean()\n",
    "\n",
    "        return mean_auc\n",
    "\n",
    "    # Create an Optuna study for maximizing AUC\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)  # You can increase n_trials for more optimization\n",
    "\n",
    "    PARAM_DT = study.best_params\n",
    "    best_auc = study.best_value\n",
    "\n",
    "    print(\"Best hyperparameters:\", PARAM_DT)\n",
    "    print(f\"Best {SCORING}:\", best_auc)\n",
    "else:\n",
    "    PARAM_DT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if HYPERTRAINING:\n",
    "    def objective(trial):\n",
    "        # Define hyperparameters to optimize\n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.3),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_child_weight': trial.suggest_uniform('min_child_weight', 1.0, 20.0),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
    "            'reg_alpha': trial.suggest_uniform('reg_alpha', 0.1, 1.0),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda', 0.01, 0.1),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        }\n",
    "        # Implement early stopping with cross-validation\n",
    "        cv_scores = []\n",
    "\n",
    "        clf = XGBClassifier(**params, random_state=42, n_jobs=-1)\n",
    "        # Implement cross-validation to calculate mean AUC\n",
    "        cv_scores = cross_val_score(clf, X_train_scaled_df, y_train, cv=CV, scoring=SCORING)\n",
    "        mean_auc = cv_scores.mean()\n",
    "\n",
    "        return mean_auc\n",
    "    # Create an Optuna study for maximizing AUC\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)  # You can increase n_trials for more optimization\n",
    "\n",
    "    PARAM_XGB = study.best_params\n",
    "    best_auc = study.best_value\n",
    "\n",
    "    print(\"Best hyperparameters:\", PARAM_XGB)\n",
    "    print(f\"Best {SCORING}:\", best_auc)\n",
    "else:\n",
    "    PARAM_XGB = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS\n",
    "- f1 Score für false Predictions -> DONE\n",
    "- save shap values für alle Modelle -> DONE\n",
    "- plots in einem Ordner saven -> DONE\n",
    "- Random State hinzufügen -> DONE\n",
    "- Vereinfachung des Codes -> DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression training----->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 234 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "Using 234 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "Using 234 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "  8%|▊         | 19/234 [00:45<08:33,  2.39s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The passed model is not callable and cannot be analyzed directly with the given masker! Model: LinearRegression()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Robert\\Documents\\Projekte\\dev\\statsfaction\\scripts\\sport_analytics\\model\\what was his name again_offense_regression.ipynb Cell 30\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Robert/Documents/Projekte/dev/statsfaction/scripts/sport_analytics/model/what%20was%20his%20name%20again_offense_regression.ipynb#X41sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m mlflow\u001b[39m.\u001b[39mlog_params(model\u001b[39m.\u001b[39mget_params())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Robert/Documents/Projekte/dev/statsfaction/scripts/sport_analytics/model/what%20was%20his%20name%20again_offense_regression.ipynb#X41sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train_scaled_df, y_train)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Robert/Documents/Projekte/dev/statsfaction/scripts/sport_analytics/model/what%20was%20his%20name%20again_offense_regression.ipynb#X41sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m plot_shap_summary(model\u001b[39m=\u001b[39;49mmodel,df\u001b[39m=\u001b[39;49mX_test_scaled_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Robert/Documents/Projekte/dev/statsfaction/scripts/sport_analytics/model/what%20was%20his%20name%20again_offense_regression.ipynb#X41sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test_scaled_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Robert/Documents/Projekte/dev/statsfaction/scripts/sport_analytics/model/what%20was%20his%20name%20again_offense_regression.ipynb#X41sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Log Params\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Robert\\Documents\\Projekte\\dev\\statsfaction\\src\\sport_analytics\\model\\eval.py:181\u001b[0m, in \u001b[0;36mplot_shap_summary\u001b[1;34m(model, df)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_shap_summary\u001b[39m(model,df):\n\u001b[1;32m--> 181\u001b[0m     explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39;49mExplainer(model)\n\u001b[0;32m    182\u001b[0m     shap_values \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39mshap_values(df)\n\u001b[0;32m    183\u001b[0m     \u001b[39m# manche Modelle liefern shap values zu positiven und negativen Prediction\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Robert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shap\\explainers\\_explainer.py:171\u001b[0m, in \u001b[0;36mExplainer.__init__\u001b[1;34m(self, model, masker, link, algorithm, output_names, feature_names, linearize_link, seed, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m             algorithm \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpermutation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    169\u001b[0m     \u001b[39m# if we get here then we don't know how to handle what was given to us\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe passed model is not callable and cannot be analyzed directly with the given masker! Model: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(model))\n\u001b[0;32m    173\u001b[0m \u001b[39m# build the right subclass\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m algorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mexact\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: The passed model is not callable and cannot be analyzed directly with the given masker! Model: LinearRegression()"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from src.sport_analytics.model.eval import plot_feature_importance, log_metrics_in_mlflow_regression, log_feature_list_as_artifact, plot_shap_summary_regression\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# (Your other imports and parameters)\n",
    "\n",
    "# Create and train different regression models\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost Regressor': xgb.XGBRegressor(random_state=42),\n",
    "    'LightGBM Regressor': lgb.LGBMRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "regression_results = {}\n",
    "\n",
    "# Set the experiment name\n",
    "mlflow.set_experiment(EXPERIEMENT_NAME)\n",
    "\n",
    "# Start MLflow run with a specific run name and description\n",
    "for model_name, model in regression_models.items():\n",
    "    with mlflow.start_run(run_name=RUN_NAME):\n",
    "\n",
    "        print(model_name, \"training----->\")\n",
    "\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"Model_Name\", model_name)\n",
    "        mlflow.log_params(model.get_params())\n",
    "\n",
    "        model.fit(X_train_scaled_df, y_train)\n",
    "        plot_shap_summary_regression(model=model,df=X_test_scaled_df)\n",
    "        y_pred = model.predict(X_test_scaled_df)\n",
    "        \n",
    "        # Log Params\n",
    "        log_feature_list_as_artifact(PLAYER_ATTRIBUTES, filename=\"feature_list.txt\")\n",
    "\n",
    "        # Create a dictionary with parameters and their values\n",
    "        params_to_log = {\n",
    "            'HYPERTRAINING': HYPERTRAINING,\n",
    "            'CV': CV,\n",
    "            'SCORING': SCORING,\n",
    "            'features_anzahl': len(PLAYER_ATTRIBUTES),\n",
    "            # 'y_train_positives': y_train.sum(),\n",
    "            # 'y_train_negatives': (~y_train).sum(),\n",
    "            # 'y_test_positives': y_test.sum(),\n",
    "            # 'y_test_negatives': (~y_test).sum(),\n",
    "            'TARGET_OVERALL': TARGET_OVERALL\n",
    "        }\n",
    "\n",
    "        # Log parameters using log_params\n",
    "        mlflow.log_params(params_to_log)\n",
    "\n",
    "        # Log artifacts\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "        # Evaluation Plots (Note: Regression models may not have ROC curves, so adapt this as needed)\n",
    "        # plot_auc_curves(y_true=y_test, y_proba=model.predict_proba(X_test_scaled_df))\n",
    "        plot_feature_importance(model, '', top_n=20)\n",
    "        \n",
    "        # Evaluation Metrics\n",
    "        log_metrics_in_mlflow_regression(y_test=y_test, y_pred=y_pred)\n",
    "\n",
    "        # Output for quick evaluation\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        regression_results[model_name] = {\n",
    "            'Model': model,\n",
    "            'Attributes': PLAYER_ATTRIBUTES,\n",
    "            'Mean Squared Error': mse,\n",
    "            'Mean Absolute Error': mae,\n",
    "            'R2 Score': r2\n",
    "        }\n",
    "\n",
    "# Evaluate and print results for each model\n",
    "for model_name, results in regression_results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Mean Squared Error: {results['Mean Squared Error']:.2f}\")\n",
    "    print(f\"Mean Absolute Error: {results['Mean Absolute Error']:.2f}\")\n",
    "    print(f\"R^2 Score: {results['R2 Score']:.2f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = regression_results['Linear Regression']['Model']\n",
    "\n",
    "true_positives = (my_model.predict(X_test_scaled_df)>=80)&(y_test>=80)\n",
    "X_test_scaled_df[true_positives]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = (my_model.predict(X_test_scaled_df)>=80)&(y_test<80)\n",
    "X_test_scaled_df[false_positives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives= (my_model.predict(X_test_scaled_df)<80)&(y_test>80)\n",
    "X_test_scaled_df[false_negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negatives= (my_model.predict(X_test_scaled_df)<80)&(y_test<80)\n",
    "X_test_scaled_df[true_negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
